# Vision Gen
Sota image/video generator collected from conferences, huggingface, github, etc.

## Image Generation
### Efficiency

<details>
  <summary><b>SDXL-Lightning</b></summary>

- [paper/report](https://arxiv.org/abs/2402.13929)
- [model](https://huggingface.co/ByteDance/SDXL-Lightning)
- [demo](https://huggingface.co/spaces/ByteDance/SDXL-Lightning)

</details>

<details>
  <summary><b>SDXS</b></summary>

- [project](https://idkiro.github.io/sdxs)
- [paper](https://arxiv.org/abs/2403.16627)
- [code](https://github.com/IDKiro/sdxs)
- [demo](https://huggingface.co/spaces/IDKiro/SDXS-512-DreamShaper)

</details>

<details>
  <summary><b>Hyper-Sd</b></summary>

- [project](https://hyper-sd.github.io/)
- [paper/report](https://arxiv.org/abs/2404.13686)
- [model](https://huggingface.co/ByteDance/Hyper-SD)
- [demo(t2i)](https://huggingface.co/spaces/ByteDance/Hyper-SDXL-1Step-T2I)
- [demo(scribble)](https://huggingface.co/spaces/ByteDance/Hyper-SD15-Scribble)

</details>

<details>
  <summary><b>SDXL-flash</b></summary>

- [model](https://huggingface.co/sd-community/sdxl-flash)

</details>

## Video Generation
### Editing

<details>
  <summary><b>DreamVideo (CVPR2024)</b></summary>

- [project](https://dreamvideo-t2v.github.io/)
- [paper](http://arxiv.org/abs/2312.04433)
- [code](https://github.com/ali-vilab/VGen)
- [model](https://modelscope.cn/models/iic/dreamvideo-t2v/summary)

</details>

### Efficiency

<details>
  <summary><b>VideoLCM</b></summary>

- [project](https://tf-t2v.github.io/)
- [paper](https://arxiv.org/abs/2312.09109)

</details>

<details>
  <summary><b>AnimateLCM</b></summary>

- [project](https://animatelcm.github.io/)
- [paper/report](https://arxiv.org/abs/2402.00769)
- [model](https://huggingface.co/wangfuyun/AnimateLCM)
- [code](https://github.com/G-U-N/AnimateLCM)
- [demo](https://huggingface.co/spaces/wangfuyun/AnimateLCM-SVD)

</details>

<details>
  <summary><b>AnimateDiff-Lightning</b></summary>

- [paper/report](https://arxiv.org/abs/2403.12706)
- [model](https://huggingface.co/ByteDance/AnimateDiff-Lightning)
- [demo](https://huggingface.co/spaces/ByteDance/AnimateDiff-Lightning)

</details>



## Useful Resources
### Paper List
- [Awesome-Diffusion-Models](https://github.com/diff-usion/Awesome-Diffusion-Models)
- [Awesome-Video-Diffusion](https://github.com/showlab/Awesome-Video-Diffusion)

### Tutorial/Docs
- [diffusers](https://huggingface.co/docs/diffusers/en/tutorials/tutorial_overview)
- [NCSN blog](https://yang-song.net/blog/2021/score/)

### Community
- [civitai](https://civitai.com/)

## Contributing
All contributions welcome! All content in this repository is licensed under the MIT license. For commercial usage, please check the license of original code/paper/project/report.